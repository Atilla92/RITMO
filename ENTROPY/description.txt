This folder contains several scripts to analyse the Pilot Sevilla Data

####
Protocol for getting all the data
####

    - Create a .csv for all subjective ratings fetched during the experiment. 
    - Create a folder with all audio data you would like to analyse.
    - Run scripts on  ***python3.10****

Script for source separation:
    0. Go to folder where all tracks are
    1. Run demucs command: demucs -n htdemucs_6s  *.wav
    2. Run renameDemucs.py to rename files with respective track name. 

Scripts for getting MIR features:
    1. Run flamenco_code_2.m in MATLAB ,
        a. The script can be found in: '/Users/atillajv/CODE/RITMO/MIR/scripts/'
        b. Run the code from the folder where your audio files are. Add this folder to your path. 
        c. A features.mat will be stored in the same folder/
        d. Copy features.mat file to '/Users/atillajv/CODE/RITMO/MIR'
    2. Run analysisMIR.py
        a. Change the name of the "features.mat" to the correspondent one.
        b. Add a folder with "features_date_XXX" to Users/atillajv/CODE/RITMO/FILES/MIR.
        c. A folder for Entropy, Novelty and SM will be created there, with all the features for each track. 

Scripts for getting entropy:
    1. For LZ-complexity run main.py  
        () Create XXXX folder in '/Users/atillajv/CODE/RITMO/ENTROPY/output/main/'
        a. Set location of folder with all audio tracks.
        b. Stores plots and csv file for each audio track in '/Users/atillajv/CODE/RITMO/ENTROPY/output/main/XXXX'
    2. Run variance.py
        a. Set location of folder with all audio tracks.
        b. Set location for output '/Users/atillajv/CODE/RITMO/ENTROPY/output/main/XXXX/var/'
        b. Stores plots and csv file for each audio track in '/Users/atillajv/CODE/RITMO/ENTROPY/output/main/var/XXXX/'
    
 Merging all data. 
    1. Run ELANanalysis.py or ELANanalysis_demucs.py if also source separated data is to be added. 
        a. Set proper location for all files starting from line 109 after try:
        b. Set name for output folder and name of file. 

There are several scripts for plots
    1. Violin Plots: plots.py
        a. Uses .csv file from ELANanalysis.py or ELANanalysis_demucs.py 
        b. Set bar_plot = False, plot_violin = True, save_violin_plot = True.
        c. Provide list on line 82 which "variables" (columns from .csv) you want to have in plot. 
        d. Change folder for saving file on line 143. 
        e. Suggestion for future: convert lines 83-143 into defintion. 

    2. HeatMap of data in plots.py:
       Get overview on how data is dritributed, takes two categories (e.g. Music_Imp, Baile_Level) as input.


    3. Ribbon plots for entropy and complexity as f(t%): plots_ribbon.py
    4. Ribbon plots for Improvisation and Flow Subjective ratings as f(t%): plots_ratings.py
    

#### TIME SERIES ####
After all of the previous steps you can also create a time-series .csv based on the online ratings of the artists. Need to run all three scripts. Script 3 uses output from script 1 and 2. 


For time series analysis:
    Time series have been binned in %time binned in 10 interval steps of 0.1. Four scripts have been made for plotting and for saving data as .csv (Run 1,2,4 for creating a .csv for further analysis) 
    1. plots_ribbon.py: works with entropy data (main/DATE/...) allows both to plot a ribbon plot of entropy and variance of entropy over time (y_var). Can both save plots and csv files. One measure at the time. 
    2. plots_ratings.py: works with FLOW and IMPRO rating files. 
    3. plots_entropy_flow.py: plot of subjective ratings versus entropy measures. 
    4. time_series.py merges Ratings and Entropy measures in one .csv file for further analysis in R. Also binned at 0.1-1, 10 intervals. 


######
A description of all the scripts can be found below.
######

cleanELAN
    If you want to replace , wtih ; and remove "" when creating new ELANannotation .csv


ELANanalysis
    Estimates average flow and improvisation rating for each ELAN annotation.
    Includes both Guitarist and Dancer


ELANanalysis_demucs (latest version)
    Same analysis as ELANanalysis yet here it adds also the estimates from separated sources for guitar and drums. 


main.py 
    Estimates the LZ entropy of audio files. 
    Need to set parameeters for window and downsampling. 
    Some of the functions are stores in functionsE.py

mean.py can probably be discarded
merge.py can probably be discarded as well. 

plots.py
    Mainly statistical plots from .csv file coming from ELANanalysis.py


renameDemucs.py 
    script can be used to copy all files with file name into new location

setWindow.py
    Used to estimate window length for data. 
    Look in the plot where fluctuations start to calm down. 

testing.py
    Sanity check with another computer whether the LZ computed renders the same values. 


variance.py
    Estimates the entropy as f(variance)
    Stores plots and outputs in seperate folder. 


######
A new series of scripts has been created to analyse the data with different OnsetDetection algorithms, followed up with a leading following analysis. All scripts start with OnsetXXX.py
######
!!!!
OnsetDetection.py - Original detection script, do not edit
PeakPicking.py - Original detection script, do not edit
PitchEstimation.py - Original detection script, do not edit
!!!!

OnsetLibrosa.py
     Testing the Librosa based onset detection algorithm. 

OnsetTesting.py
    Uses the original detection scripts. A different based onset detection algorithm. 
    For now has not been implemented in OnsetMain.py because it raises an error when trying to downsample the .wav files. For larger downsampling values than 8. 

OnsetMain.py
    Uses the librosas onset detection algorithm. The .wav file is not downsample for this, as the algorithm works best on the original sampling rate. After that the resulting binarised array is spaced at dt interval (0.001 works good enough) and the step_size (window_size) for the LZ-estimation is estimated based on a desired dt_interval (set in the beginning). 
    There is no downsampling of the .wav file needed. Plots will show both LZ, and dt_LZ.
    LZ, dt_LZ, IOI and time are stored in separate .csv files for each file_name. Plots for all files are stored as well.

OnsetLeadingFollowing.py
    After running OnsetMain.py both for guitarist and drums (dancer) a sync analysis (leading following) can be done, you can change the time_lags you want (depending on the dt from OnsetMain.py giher values will make more sense than others).
    - speficy amount of time_lags
    - specify who is leading "Dancer" or "Guitarist"
    - stores .csv as output, with "Dancer" or "Guittarist" in name. 
    - First row of .csv file will contain the average sum for the specific time_lag, you can compare them and see for which lag the duo is most in sync. 

    The algorithm compares dt_LZ of Guitarist and Dancer at a specific time lag. If both have the same sign (+,+)(-,-) a value of 1 is given, else 0. It's the simplest version of seeing whether one is following the other in terms of complexity. One could also do this for dt_IOI, this however has not been implemented yet. 

    !! Might get a runtime warning, just abort mission and restart. It will skip the files that already have been analysed. 


ELANonset.py
    Run this script in the end to merge all the estimations in one .csv file. It needs the 
    - leading following .csv from OnsetLeadingFollowing for both Guitarist and Dancer as leader, if not comment out. It also takes lag_0 from the .csv, check whether these are the highest values for both cases, else change it to a different lag that is more prevalent.
    - main .csv from experiment containing all subjective ratings. 
    - .csv files containing LZ, dt_LZ and IOI for each recording (name_file).

    Make sure you have all the paths correctly. There is a bug in the script so all files will be stored in the "error" logged json file.  
    

#### Scripts for using Niels onset detection

Assuming you have first run onsetNiels.m and performed onset detection and intensity analysis for audio files.  

extractOnsetNiels.py
    Run this script to save the onset times and onset intensity times in a new output folder, in correct dataframe format (two columns: t_onset, int_onset) for further analysis. 
    Provide input and output folder. Currently files are saved in "/Users/atillajv/CODE/RITMO/source_separation/ONSET"

OnsetNielsMain.py
    Run script to estimate entropy based on onset detection from Niels. 
    










